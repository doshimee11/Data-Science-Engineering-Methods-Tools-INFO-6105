{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNpMV5c898sz"
      },
      "source": [
        "# **CNN and ResNet Assignments**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StUsxk_094h8"
      },
      "source": [
        "Apply the CNN and ResNet models on the cifar-10 dataset to classify images. You can start with the code at Kera's site BUT observe the effects on accuracy by adding/reducing extra convolution, dropout, and batch normalization layers. Prepare about six slides to present your findings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhB62war-FkF"
      },
      "source": [
        "### **Applying CNN Model on cifar-10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBhpChjkNGYf",
        "outputId": "90acd397-ca04-4c68-9489-7006fff5ae21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "! pip install keras\n",
        "! pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FZXvxHRdMi9k"
      },
      "outputs": [],
      "source": [
        "# https://keras.io/examples/cifar10_cnn/\n",
        "\n",
        "from __future__ import print_function\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "import os\n",
        "from math import ceil\n",
        "\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 6\n",
        "data_augmentation = True\n",
        "num_predictions = 20\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'keras_cifar10_trained_model.h5'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bImaBkwRMkB2",
        "outputId": "a38205ea-2073-44a3-fa28-1597efcff424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 2s 0us/step\n",
            "[[3]\n",
            " [8]\n",
            " [8]\n",
            " ...\n",
            " [5]\n",
            " [1]\n",
            " [7]]\n",
            "\n",
            "X_Train shape: (50000, 32, 32, 3) \n",
            "\n",
            "50000 Training samples\n",
            "10000 Testing samples\n"
          ]
        }
      ],
      "source": [
        "# The data, split between train and test datasets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(y_test)\n",
        "print('\\nX_Train shape:', x_train.shape,'\\n')\n",
        "print(x_train.shape[0], 'Training samples')\n",
        "print(x_test.shape[0], 'Testing samples')\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Original Model 1\n",
        "n_points = len(x_train)\n",
        "steps_per_epoch = ceil(n_points / batch_size)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LPIMSzP3mXe",
        "outputId": "b9301f61-bf9a-4cc7-f517-815b90899d38"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2304)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1180160   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/rmsprop.py:135: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        steps_per_epoch=steps_per_epoch, # SUBRATA added\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path = os.path.join(save_dir, model_name)\n",
        "model.save(model_path)\n",
        "print('Saved trained model at %s ' % model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5JCggs83xm_",
        "outputId": "942f0681-d8ae-4233-d15c-1267faa8f357"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 176s 112ms/step - loss: 1.8432 - accuracy: 0.3188 - val_loss: 1.5251 - val_accuracy: 0.4411\n",
            "Epoch 2/6\n",
            "1563/1563 [==============================] - 167s 107ms/step - loss: 1.5724 - accuracy: 0.4262 - val_loss: 1.3720 - val_accuracy: 0.5044\n",
            "Epoch 3/6\n",
            "1563/1563 [==============================] - 168s 107ms/step - loss: 1.4595 - accuracy: 0.4716 - val_loss: 1.3047 - val_accuracy: 0.5294\n",
            "Epoch 4/6\n",
            "1563/1563 [==============================] - 180s 115ms/step - loss: 1.3753 - accuracy: 0.5056 - val_loss: 1.2499 - val_accuracy: 0.5534\n",
            "Epoch 5/6\n",
            "1563/1563 [==============================] - 179s 115ms/step - loss: 1.3112 - accuracy: 0.5310 - val_loss: 1.1814 - val_accuracy: 0.5739\n",
            "Epoch 6/6\n",
            "1563/1563 [==============================] - 177s 113ms/step - loss: 1.2505 - accuracy: 0.5554 - val_loss: 1.0852 - val_accuracy: 0.6128\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "model1acc = scores[1]\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PotAnKZp34JI",
        "outputId": "7eb613be-d80c-47de-c89b-e78b65201518"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 26ms/step - loss: 1.0852 - accuracy: 0.6128\n",
            "Test loss: 1.085150122642517\n",
            "Test accuracy: 0.6128000020980835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CKKckyaMMoPz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98492c23-166d-4805-d1d2-79b1a7f0330f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 8s 26ms/step\n"
          ]
        }
      ],
      "source": [
        "model_path = os.path.join(save_dir, model_name)\n",
        "model2 = load_model(model_path)\n",
        "#model.compile(optimizer=opt, loss='categorical_crossentropy')\n",
        "y_predict = model2.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "rSzw9olkMn0h",
        "outputId": "a557abe2-29fd-4ed9-f037-f71e50fa5a30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3) (10000, 10)\n",
            "[0.00435877 0.00120485 0.0426312  0.43741065 0.01294268 0.4152494\n",
            " 0.07150008 0.00832442 0.00467198 0.001706  ]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "print(x_test.shape, y_test.shape)\n",
        "#img=mpimg.imread(x_test[0])\n",
        "#imgplot = plt.imshow(img)\n",
        "#plt.show()\n",
        "plt.imshow(x_test[0])\n",
        "print(y_predict[0])\n",
        "print(y_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HYLwxNu3MoWY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb61257-b5f6-457f-bca5-dcd06dd5d2fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation_6 (Activation)   (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " activation_7 (Activation)   (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " activation_8 (Activation)   (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "                                                                 \n",
            " activation_9 (Activation)   (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 6, 6, 128)         8320      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 6, 6, 128)        512       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation_10 (Activation)  (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 6, 6, 256)         295168    \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 4, 4, 256)         590080    \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 2, 2, 256)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 2, 2, 256)         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,489,578\n",
            "Trainable params: 1,489,322\n",
            "Non-trainable params: 256\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model 2\n",
        "n_points = len(x_train)\n",
        "steps_per_epoch = ceil(n_points / batch_size)\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, (3, 3), padding='same',\n",
        "                 input_shape=x_train.shape[1:]))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv2D(32, (3, 3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv2D(64, (3, 3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Dense(128))\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Conv2D(256, (3, 3), padding='same'))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Conv2D(256, (3, 3)))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model2.add(Dropout(0.25))\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(512))\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.5))\n",
        "model2.add(Dense(num_classes))\n",
        "model2.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model2.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzrPIl27OQjb",
        "outputId": "a86f854b-2210-423b-b20b-e320bb089707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using real-time data augmentation.\n",
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:55: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 329s 210ms/step - loss: 2.0782 - accuracy: 0.2030 - val_loss: 2.1053 - val_accuracy: 0.2302\n",
            "Epoch 2/6\n",
            "1563/1563 [==============================] - 389s 249ms/step - loss: 1.8443 - accuracy: 0.3090 - val_loss: 4.8401 - val_accuracy: 0.1854\n",
            "Epoch 3/6\n",
            "1563/1563 [==============================] - 355s 227ms/step - loss: 1.7115 - accuracy: 0.3684 - val_loss: 1.6581 - val_accuracy: 0.3917\n",
            "Epoch 4/6\n",
            "1563/1563 [==============================] - 325s 208ms/step - loss: 1.6172 - accuracy: 0.4105 - val_loss: 1.9673 - val_accuracy: 0.3421\n",
            "Epoch 5/6\n",
            "1563/1563 [==============================] - 324s 207ms/step - loss: 1.5551 - accuracy: 0.4363 - val_loss: 2.0140 - val_accuracy: 0.3263\n",
            "Epoch 6/6\n",
            "1563/1563 [==============================] - 325s 208ms/step - loss: 1.4884 - accuracy: 0.4621 - val_loss: 2.5532 - val_accuracy: 0.3187\n",
            "Saved trained model at /content/saved_models/keras_cifar10_trained_model.h5 \n"
          ]
        }
      ],
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model2.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        # randomly shift images horizontally (fraction of total width)\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically (fraction of total height)\n",
        "        height_shift_range=0.1,\n",
        "        shear_range=0.,  # set range for random shear\n",
        "        zoom_range=0.,  # set range for random zoom\n",
        "        channel_shift_range=0.,  # set range for random channel shifts\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        cval=0.,  # value used for fill_mode = \"constant\"\n",
        "        horizontal_flip=True,  # randomly flip images\n",
        "        vertical_flip=False,  # randomly flip images\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for feature-wise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model2.fit_generator(datagen.flow(x_train, y_train,\n",
        "                                     batch_size=batch_size),\n",
        "                        steps_per_epoch=steps_per_epoch, # SUBRATA added\n",
        "                        epochs=epochs,\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        workers=4)\n",
        "\n",
        "# Save model and weights\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "model_path2 = os.path.join(save_dir, model_name)\n",
        "model2.save(model_path2)\n",
        "print('Saved trained model at %s ' % model_path2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores2 = model2.evaluate(x_test, y_test, verbose=1)\n",
        "model2acc = scores2[1]\n",
        "print('Test loss:', scores2[0])\n",
        "print('Test accuracy:', scores2[1])"
      ],
      "metadata": {
        "id": "o6v0Ryyv2Shu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de183b8-9faf-40c0-a48b-c1c419c57acc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 13s 40ms/step - loss: 2.5532 - accuracy: 0.3187\n",
            "Test loss: 2.5532214641571045\n",
            "Test accuracy: 0.31869998574256897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path2 = os.path.join(save_dir, model_name)\n",
        "model22 = load_model(model_path2)\n",
        "#model.compile(optimizer=opt, loss='categorical_crossentropy')\n",
        "y_predict2 = model22.predict(x_test)"
      ],
      "metadata": {
        "id": "ZWpJTStk2XNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe1b19b1-51c3-423d-bff1-43244b236c14"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 13s 42ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "print(x_test.shape, y_test.shape)\n",
        "#img=mpimg.imread(x_test[0])\n",
        "#imgplot = plt.imshow(img)\n",
        "#plt.show()\n",
        "plt.imshow(x_test[0])\n",
        "print(y_predict2[0])\n",
        "print(y_test[0])"
      ],
      "metadata": {
        "id": "5DKXaDDL2ay9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "outputId": "8372c035-9995-43b3-b835-37295764178c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 32, 32, 3) (10000, 10)\n",
            "[1.64441706e-04 5.88374423e-05 1.31098777e-01 3.68854403e-02\n",
            " 9.12984759e-02 6.80154609e-03 7.32149601e-01 1.35538646e-03\n",
            " 7.22647310e-05 1.15245915e-04]\n",
            "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALlklEQVR4nO3db6hk9X3H8fen/mlLFOLWdllWU6OVlhBSFZEUJNhAgvWJCkUMBLYQuCFE0AeFSgqN7aOkREMfWWxdspTW1NamipQaKxbzyLjadd11m6hBicvqEmxQnyQ1fvtgztK7y869s3fOzOz6fb9gmDO/Ofec7/7Yz5zfOXPv+aWqkPTB90urLkDSchh2qQnDLjVh2KUmDLvUhGGXmjh7nh9Ocj3wV8BZwN9W1dc2Wd/v+aQFq6qcrD1b/Z49yVnAD4HPAK8DzwCfq6oXN/gZwy4t2LSwzzOMvwZ4uap+VFU/B74N3DjH9iQt0Dxh3wn8eN3r14c2Saehuc7ZZ5FkDVhb9H4kbWyesB8GLl73+qKh7ThVdR9wH3jOLq3SPMP4Z4DLk3w0ybnArcAj45QlaWxbPrJX1XtJbgMeY/LV2+6qOjhaZZJGteWv3ra0M4fx0sIt4qs3SWcQwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqmJuWZxTfIq8A7wC+C9qrp6jKIkjW+MKZt/v6p+MsJ2JC2Qw3ipiXnDXsB3kzybZG2MgiQtxrzD+Gur6nCS3wAeT/LfVfXU+hWGDwE/CKQVG23K5iR3Ae9W1Tc2WMcpm6UFG33K5iQfSnL+sWXgs8CBrW5P0mLNM4zfDnwnybHt/ENV/fsoVUka3WjD+Jl25jBeWrjRh/GSziyGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhObhj3J7iRHkxxY17YtyeNJXhqeL1hsmZLmNcuR/VvA9Se03Qk8UVWXA08MryWdxjYN+zDf+lsnNN8I7BmW9wA3jVyXpJFt9Zx9e1UdGZbfYDKjq6TT2DxTNgNQVbXR7KxJ1oC1efcjaT5bPbK/mWQHwPB8dNqKVXVfVV1dVVdvcV+SRrDVsD8C7BqWdwEPj1OOpEVJ1dQR+GSF5AHgOuBC4E3gq8C/Ag8CHwFeA26pqhMv4p1sWxvvTNLcqiona9807GMy7NLiTQu7v0EnNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNbFp2JPsTnI0yYF1bXclOZxk3/C4YbFlSprXLEf2bwHXn6T9m1V1xfD4t3HLkjS2TcNeVU8Bm07aKOn0Ns85+21J9g/D/AtGq0jSQmw17PcClwFXAEeAu6etmGQtyd4ke7e4L0kjmGnK5iSXAI9W1cdP5b2TrOuUzdKCjTplc5Id617eDByYtq6k08PZm62Q5AHgOuDCJK8DXwWuS3IFUMCrwBcXWKOkEcw0jB9tZw7jpYUbdRgv6cxj2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjWxadiTXJzkySQvJjmY5PahfVuSx5O8NDw7bbN0Gtt0+qdhEscdVfVckvOBZ4GbgD8C3qqqryW5E7igqv5kk205/ZO0YFue/qmqjlTVc8PyO8AhYCdwI7BnWG0Pkw8ASaepUzpnH+ZivxJ4GtheVUeGt94Ato9amaRRbTpl8zFJzgMeAu6oqreT/x8pVFVNG6InWQPW5i1U0nxmmrI5yTnAo8BjVXXP0PYD4LqqOjKc1/9nVf32JtvxnF1asC2fs2dyCL8fOHQs6INHgF3D8i7g4XmLlLQ4s1yNvxb4HvAC8P7Q/BUm5+0PAh8BXgNuqaq3NtmWR3ZpwaYd2Wcaxo/FsEuLt+VhvKQPBsMuNWHYpSYMu9SEYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapiVnmers4yZNJXkxyMMntQ/tdSQ4n2Tc8blh8uauVKQ/pTDDLXG87gB1V9VyS84FngZuAW4B3q+obM+/sDJ/+aVqwz+h/lD5wpk3/tOn87FV1BDgyLL+T5BCwc9zyJC3aKZ2zJ7kEuJLJDK4AtyXZn2R3kgtGrk3SiGYOe5LzgIeAO6rqbeBe4DLgCiZH/run/Nxakr1J9o5Qr6QtmmnK5iTnAI8Cj1XVPSd5/xLg0ar6+CbbOaNPbz1n15lgy1M2JwlwP3BofdCHC3fH3AwcmLdISYszy9X4a4HvAS8A7w/NXwE+x2QIX8CrwBeHi3kbbcuDoLRg047sMw3jx2LYpcXb8jBe0geDYZeaMOxSE4ZdasKwS00YdqkJwy41YdilJgy71IRhl5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9TELHO9/UqS7yd5PsnBJH8+tH80ydNJXk7yj0nOXXy5krZqliP7z4BPV9XvMpnb7foknwS+Dnyzqn4L+B/gC4srU9K8Ng17Tbw7vDxneBTwaeCfh/Y9wE0LqVDSKGY6Z09yVpJ9wFHgceAV4KdV9d6wyuvAzsWUKGkMM4W9qn5RVVcAFwHXAL8z6w6SrCXZm2TvFmuUNIJTuhpfVT8FngR+D/hwkrOHty4CDk/5mfuq6uqqunquSiXNZZar8b+e5MPD8q8CnwEOMQn9Hw6r7QIeXlSRkuaXqtp4heQTTC7AncXkw+HBqvqLJJcC3wa2Af8FfL6qfrbJtjbemaS5VVVO1r5p2Mdk2KXFmxZ2f4NOasKwS00YdqkJwy41YdilJs7efJVR/QR4bVi+cHi9atZxPOs43plWx29Oe2OpX70dt+Nk7+nwW3XWYR1d6nAYLzVh2KUmVhn2+1a47/Ws43jWcbwPTB0rO2eXtFwO46UmVhL2JNcn+cFws8o7V1HDUMerSV5Ism+ZN9dIsjvJ0SQH1rVtS/J4kpeG5wtWVMddSQ4PfbIvyQ1LqOPiJE8meXG4qentQ/tS+2SDOpbaJwu7yWtVLfXB5E9lXwEuBc4Fngc+tuw6hlpeBS5cwX4/BVwFHFjX9pfAncPyncDXV1THXcAfL7k/dgBXDcvnAz8EPrbsPtmgjqX2CRDgvGH5HOBp4JPAg8CtQ/tfA186le2u4sh+DfByVf2oqn7O5G/ib1xBHStTVU8Bb53QfCOT+wbAkm7gOaWOpauqI1X13LD8DpObo+xkyX2yQR1LVROj3+R1FWHfCfx43etV3qyygO8meTbJ2opqOGZ7VR0Zlt8Atq+wltuS7B+G+Qs/nVgvySXAlUyOZivrkxPqgCX3ySJu8tr9At21VXUV8AfAl5N8atUFweSTnckH0SrcC1zGZI6AI8Ddy9pxkvOAh4A7qurt9e8ts09OUsfS+6TmuMnrNKsI+2Hg4nWvp96sctGq6vDwfBT4DpNOXZU3k+wAGJ6PrqKIqnpz+I/2PvA3LKlPkpzDJGB/X1X/MjQvvU9OVseq+mTY9ynf5HWaVYT9GeDy4criucCtwCPLLiLJh5Kcf2wZ+CxwYOOfWqhHmNy4E1Z4A89j4RrczBL6JEmA+4FDVXXPureW2ifT6lh2nyzsJq/LusJ4wtXGG5hc6XwF+NMV1XApk28CngcOLrMO4AEmw8H/ZXLu9QXg14AngJeA/wC2raiOvwNeAPYzCduOJdRxLZMh+n5g3/C4Ydl9skEdS+0T4BNMbuK6n8kHy5+t+z/7feBl4J+AXz6V7fobdFIT3S/QSW0YdqkJwy41YdilJgy71IRhl5ow7FIThl1q4v8Ai3MOFJpGejgAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Comparison of Models\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"Testing Accuarcy of Original Model without any addition\")\n",
        "print(\"Testing Accuracy:\",(model1acc)*100,\"%\")\n",
        "print(\"\")\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"Testing Accuarcy of Model with extra layer of Batch Normalization and Convolution Layer\")\n",
        "print(\"Testing Accuracy:\",(model2acc)*100,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mVUHVoJjbr3",
        "outputId": "dd61f261-802d-40b2-9043-4196eb8ee633"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n",
            "Testing Accuarcy of Original Model without any addition\n",
            "Testing Accuracy: 61.28000020980835 %\n",
            "\n",
            "--------------------------------------------\n",
            "Testing Accuarcy of Model with extra layer of Batch Normalization and Convolution Layer\n",
            "Testing Accuracy: 31.869998574256897 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRR1fIph-TKk"
      },
      "source": [
        "### **Applying ResNet Model on cifar-10 dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uPIVnY7t-swZ"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
        "from keras.layers import AveragePooling2D, Input, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.datasets import cifar10\n",
        "import numpy as np\n",
        "import os\n",
        "from math import ceil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "XXc4RL7u-sot",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285d9644-0d01-4521-eb22-22d2adf9d521"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "y_train shape: (50000, 1)\n"
          ]
        }
      ],
      "source": [
        "# Training parameters\n",
        "batch_size = 32\n",
        "epochs = 4\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n = 3\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version == 1:\n",
        "    depth = n * 6 + 2\n",
        "elif version == 2:\n",
        "    depth = n * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "# SUBRATA added\n",
        "n_points = len(x_train)\n",
        "steps_per_epoch = ceil(n_points / batch_size)\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('y_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "NCRJJdbp-sfb"
      },
      "outputs": [],
      "source": [
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation='relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv2D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = Activation('relu')(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet_v2(input_shape, depth, num_classes=10):\n",
        "    \"\"\"ResNet Version 2 Model builder [b]\n",
        "\n",
        "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
        "    bottleneck layer\n",
        "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
        "    Second and onwards shortcut connection is identity.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filter maps is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same filter map sizes.\n",
        "    Features maps sizes:\n",
        "    conv1  : 32x32,  16\n",
        "    stage 0: 32x32,  64\n",
        "    stage 1: 16x16, 128\n",
        "    stage 2:  8x8,  256\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 9 != 0:\n",
        "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
        "    # Start model definition.\n",
        "    num_filters_in = 16\n",
        "    num_res_blocks = int((depth - 2) / 9)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
        "    x = resnet_layer(inputs=inputs,\n",
        "                     num_filters=num_filters_in,\n",
        "                     conv_first=True)\n",
        "\n",
        "    # Instantiate the stack of residual units\n",
        "    for stage in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            activation = 'relu'\n",
        "            batch_normalization = True\n",
        "            strides = 1\n",
        "            if stage == 0:\n",
        "                num_filters_out = num_filters_in * 4\n",
        "                if res_block == 0:  # first layer and first stage\n",
        "                    activation = None\n",
        "                    batch_normalization = False\n",
        "            else:\n",
        "                num_filters_out = num_filters_in * 2\n",
        "                if res_block == 0:  # first layer but not first stage\n",
        "                    strides = 2    # downsample\n",
        "\n",
        "            # bottleneck residual unit\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters_in,\n",
        "                             kernel_size=1,\n",
        "                             strides=strides,\n",
        "                             activation=activation,\n",
        "                             batch_normalization=batch_normalization,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_in,\n",
        "                             conv_first=False)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters_out,\n",
        "                             kernel_size=1,\n",
        "                             conv_first=False)\n",
        "            if res_block == 0:\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters_out,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "\n",
        "        num_filters_in = num_filters_out\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v2 has BN-ReLU before Pooling\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = AveragePooling2D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FcY70lKz-sY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90286026-087f-42ff-a469-6376c7e69cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 16)   448         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_15[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_11[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_16[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_12[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 16)   0           ['activation_15[0][0]',          \n",
            "                                                                  'batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_13[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_18 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_18[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_14[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 16)   0           ['activation_17[0][0]',          \n",
            "                                                                  'batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " activation_19 (Activation)     (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_19[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_15[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_20 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_20[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_16[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 16)   0           ['activation_19[0][0]',          \n",
            "                                                                  'batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " activation_21 (Activation)     (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 16, 16, 32)   4640        ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_17[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_22 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_22[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 32)   544         ['activation_21[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_18[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 16, 16, 32)   0           ['conv2d_19[0][0]',              \n",
            "                                                                  'batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " activation_23 (Activation)     (None, 16, 16, 32)   0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_23[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 16, 16, 32)  128         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_24 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_24[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 16, 16, 32)  128         ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 16, 16, 32)   0           ['activation_23[0][0]',          \n",
            "                                                                  'batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " activation_25 (Activation)     (None, 16, 16, 32)   0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_25[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 16, 32)  128         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_26 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_26[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 16, 32)  128         ['conv2d_23[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 16, 16, 32)   0           ['activation_25[0][0]',          \n",
            "                                                                  'batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " activation_27 (Activation)     (None, 16, 16, 32)   0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 8, 8, 64)     18496       ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 8, 8, 64)    256         ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_28 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_28[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 8, 8, 64)     2112        ['activation_27[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 8, 8, 64)    256         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 8, 8, 64)     0           ['conv2d_26[0][0]',              \n",
            "                                                                  'batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " activation_29 (Activation)     (None, 8, 8, 64)     0           ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_29[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 8, 8, 64)    256         ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_30 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_30[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 8, 8, 64)     0           ['activation_29[0][0]',          \n",
            "                                                                  'batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " activation_31 (Activation)     (None, 8, 8, 64)     0           ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_31[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 8, 8, 64)    256         ['conv2d_29[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_32 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_32[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 8, 8, 64)    256         ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 8, 8, 64)     0           ['activation_31[0][0]',          \n",
            "                                                                  'batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " activation_33 (Activation)     (None, 8, 8, 64)     0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " average_pooling2d (AveragePool  (None, 1, 1, 64)    0           ['activation_33[0][0]']          \n",
            " ing2D)                                                                                           \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 64)           0           ['average_pooling2d[0][0]']      \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 10)           650         ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 274,442\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 273,066\n",
            "Non-trainable params: 1,376\n",
            "__________________________________________________________________________________________________\n",
            "ResNet20v1\n"
          ]
        }
      ],
      "source": [
        "if version == 2:\n",
        "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
        "else:\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "print(model_type)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs, verbose=1, workers=4,\n",
        "                        steps_per_epoch=steps_per_epoch,\n",
        "                        callbacks=callbacks)"
      ],
      "metadata": {
        "id": "y2IS5QFk4mEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "404f66f5-d8c5-4b2e-e6ed-59e2e2cb6d62"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:86: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - ETA: 0s - loss: 1.5830 - accuracy: 0.4849"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 430s 273ms/step - loss: 1.5830 - accuracy: 0.4849 - val_loss: 1.4443 - val_accuracy: 0.5525 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.1952 - accuracy: 0.6321"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 425s 272ms/step - loss: 1.1952 - accuracy: 0.6321 - val_loss: 1.5014 - val_accuracy: 0.5492 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.0270 - accuracy: 0.6958"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1563 [==============================] - 425s 272ms/step - loss: 1.0270 - accuracy: 0.6958 - val_loss: 1.1340 - val_accuracy: 0.6665 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.9298 - accuracy: 0.7333"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1563 [==============================] - 427s 273ms/step - loss: 0.9298 - accuracy: 0.7333 - val_loss: 0.9814 - val_accuracy: 0.7185 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8oaFXGTk-sRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c78bedc-4530-4463-f17f-78aac153c74d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 29s 92ms/step - loss: 0.9814 - accuracy: 0.7185\n",
            "Test loss: 0.9814386963844299\n",
            "Test accuracy: 0.718500018119812\n"
          ]
        }
      ],
      "source": [
        "# Score trained model.\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\n",
        "resnetmodel1acc = scores[1]\n",
        "print('Test loss:', scores[0])\n",
        "print('Test accuracy:', scores[1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters of original resnet model\n",
        "batch_size = 32\n",
        "epochs1 = 4\n",
        "data_augmentation = True\n",
        "num_classes = 10\n",
        "\n",
        "# Subtracting pixel mean improves accuracy\n",
        "subtract_pixel_mean = True\n",
        "\n",
        "# Model parameter\n",
        "# ----------------------------------------------------------------------------\n",
        "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
        "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
        "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
        "# ----------------------------------------------------------------------------\n",
        "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
        "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
        "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
        "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
        "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
        "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
        "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
        "# ---------------------------------------------------------------------------\n",
        "n1 = 5\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version1 = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "if version1 == 1:\n",
        "    depth1 = n1 * 6 + 2\n",
        "elif version1 == 2:\n",
        "    depth1 = n1 * 9 + 2\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type1 = 'ResNet%dv%d' % (depth1, version1)\n",
        "\n",
        "# Load the CIFAR10 data.\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Input image dimensions.\n",
        "input_shape = x_train.shape[1:]\n",
        "\n",
        "# Normalize data.\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "n_points = len(x_train)\n",
        "steps_per_epoch = ceil(n_points / batch_size)\n",
        "\n",
        "# If subtract pixel mean is enabled\n",
        "if subtract_pixel_mean:\n",
        "    x_train_mean = np.mean(x_train, axis=0)\n",
        "    x_train -= x_train_mean\n",
        "    x_test -= x_train_mean\n",
        "\n",
        "print('X_Train shape:', x_train.shape,'\\n')\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "print('\\nY_train shape:', y_train.shape)\n",
        "\n",
        "# Convert class vectors to binary class matrices.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHgzmiqkkc81",
        "outputId": "1629da59-0698-4822-f98e-0ef26645cd78"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_Train shape: (50000, 32, 32, 3) \n",
            "\n",
            "50000 train samples\n",
            "10000 test samples\n",
            "\n",
            "Y_train shape: (50000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if version1 == 2:\n",
        "    model1 = resnet_v2(input_shape=input_shape, depth=depth1)\n",
        "else:\n",
        "    model1 = resnet_v1(input_shape=input_shape, depth=depth1)\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(lr=lr_schedule(0)),\n",
        "              metrics=['accuracy'])\n",
        "model1.summary()\n",
        "print(model_type1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CeaaX1Tkq59",
        "outputId": "0bc7c292-364b-4db6-cc72-ed557dd19886"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate:  0.001\n",
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_176 (Conv2D)            (None, 32, 32, 16)   448         ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_160 (Batch  (None, 32, 32, 16)  64          ['conv2d_176[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_174 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_160[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_177 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_174[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_161 (Batch  (None, 32, 32, 16)  64          ['conv2d_177[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_175 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_161[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_178 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_175[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_162 (Batch  (None, 32, 32, 16)  64          ['conv2d_178[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_60 (Add)                   (None, 32, 32, 16)   0           ['activation_174[0][0]',         \n",
            "                                                                  'batch_normalization_162[0][0]']\n",
            "                                                                                                  \n",
            " activation_176 (Activation)    (None, 32, 32, 16)   0           ['add_60[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_179 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_176[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_163 (Batch  (None, 32, 32, 16)  64          ['conv2d_179[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_177 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_163[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_180 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_177[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_164 (Batch  (None, 32, 32, 16)  64          ['conv2d_180[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_61 (Add)                   (None, 32, 32, 16)   0           ['activation_176[0][0]',         \n",
            "                                                                  'batch_normalization_164[0][0]']\n",
            "                                                                                                  \n",
            " activation_178 (Activation)    (None, 32, 32, 16)   0           ['add_61[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_181 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_178[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_165 (Batch  (None, 32, 32, 16)  64          ['conv2d_181[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_179 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_165[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_182 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_179[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_166 (Batch  (None, 32, 32, 16)  64          ['conv2d_182[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_62 (Add)                   (None, 32, 32, 16)   0           ['activation_178[0][0]',         \n",
            "                                                                  'batch_normalization_166[0][0]']\n",
            "                                                                                                  \n",
            " activation_180 (Activation)    (None, 32, 32, 16)   0           ['add_62[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_183 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_180[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_167 (Batch  (None, 32, 32, 16)  64          ['conv2d_183[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_181 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_167[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_184 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_181[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_168 (Batch  (None, 32, 32, 16)  64          ['conv2d_184[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_63 (Add)                   (None, 32, 32, 16)   0           ['activation_180[0][0]',         \n",
            "                                                                  'batch_normalization_168[0][0]']\n",
            "                                                                                                  \n",
            " activation_182 (Activation)    (None, 32, 32, 16)   0           ['add_63[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_185 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_182[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_169 (Batch  (None, 32, 32, 16)  64          ['conv2d_185[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_183 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_169[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_186 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_183[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_170 (Batch  (None, 32, 32, 16)  64          ['conv2d_186[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_64 (Add)                   (None, 32, 32, 16)   0           ['activation_182[0][0]',         \n",
            "                                                                  'batch_normalization_170[0][0]']\n",
            "                                                                                                  \n",
            " activation_184 (Activation)    (None, 32, 32, 16)   0           ['add_64[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_187 (Conv2D)            (None, 16, 16, 32)   4640        ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_171 (Batch  (None, 16, 16, 32)  128         ['conv2d_187[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_185 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_171[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_188 (Conv2D)            (None, 16, 16, 32)   9248        ['activation_185[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_189 (Conv2D)            (None, 16, 16, 32)   544         ['activation_184[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_172 (Batch  (None, 16, 16, 32)  128         ['conv2d_188[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_65 (Add)                   (None, 16, 16, 32)   0           ['conv2d_189[0][0]',             \n",
            "                                                                  'batch_normalization_172[0][0]']\n",
            "                                                                                                  \n",
            " activation_186 (Activation)    (None, 16, 16, 32)   0           ['add_65[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_190 (Conv2D)            (None, 16, 16, 32)   9248        ['activation_186[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_173 (Batch  (None, 16, 16, 32)  128         ['conv2d_190[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_187 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_173[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_191 (Conv2D)            (None, 16, 16, 32)   9248        ['activation_187[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_174 (Batch  (None, 16, 16, 32)  128         ['conv2d_191[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_66 (Add)                   (None, 16, 16, 32)   0           ['activation_186[0][0]',         \n",
            "                                                                  'batch_normalization_174[0][0]']\n",
            "                                                                                                  \n",
            " activation_188 (Activation)    (None, 16, 16, 32)   0           ['add_66[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_192 (Conv2D)            (None, 16, 16, 32)   9248        ['activation_188[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_175 (Batch  (None, 16, 16, 32)  128         ['conv2d_192[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_189 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_175[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_193 (Conv2D)            (None, 16, 16, 32)   9248        ['activation_189[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_176 (Batch  (None, 16, 16, 32)  128         ['conv2d_193[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_67 (Add)                   (None, 16, 16, 32)   0           ['activation_188[0][0]',         \n",
            "                                                                  'batch_normalization_176[0][0]']\n",
            "                                                                                                  \n",
            " activation_190 (Activation)    (None, 16, 16, 32)   0           ['add_67[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_194 (Conv2D)            (None, 16, 16, 32)   9248        ['activation_190[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_177 (Batch  (None, 16, 16, 32)  128         ['conv2d_194[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_191 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_177[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_195 (Conv2D)            (None, 16, 16, 32)   9248        ['activation_191[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_178 (Batch  (None, 16, 16, 32)  128         ['conv2d_195[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_68 (Add)                   (None, 16, 16, 32)   0           ['activation_190[0][0]',         \n",
            "                                                                  'batch_normalization_178[0][0]']\n",
            "                                                                                                  \n",
            " activation_192 (Activation)    (None, 16, 16, 32)   0           ['add_68[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_196 (Conv2D)            (None, 16, 16, 32)   9248        ['activation_192[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_179 (Batch  (None, 16, 16, 32)  128         ['conv2d_196[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_193 (Activation)    (None, 16, 16, 32)   0           ['batch_normalization_179[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_197 (Conv2D)            (None, 16, 16, 32)   9248        ['activation_193[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_180 (Batch  (None, 16, 16, 32)  128         ['conv2d_197[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_69 (Add)                   (None, 16, 16, 32)   0           ['activation_192[0][0]',         \n",
            "                                                                  'batch_normalization_180[0][0]']\n",
            "                                                                                                  \n",
            " activation_194 (Activation)    (None, 16, 16, 32)   0           ['add_69[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_198 (Conv2D)            (None, 8, 8, 64)     18496       ['activation_194[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_181 (Batch  (None, 8, 8, 64)    256         ['conv2d_198[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_195 (Activation)    (None, 8, 8, 64)     0           ['batch_normalization_181[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_199 (Conv2D)            (None, 8, 8, 64)     36928       ['activation_195[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_200 (Conv2D)            (None, 8, 8, 64)     2112        ['activation_194[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_182 (Batch  (None, 8, 8, 64)    256         ['conv2d_199[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_70 (Add)                   (None, 8, 8, 64)     0           ['conv2d_200[0][0]',             \n",
            "                                                                  'batch_normalization_182[0][0]']\n",
            "                                                                                                  \n",
            " activation_196 (Activation)    (None, 8, 8, 64)     0           ['add_70[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_201 (Conv2D)            (None, 8, 8, 64)     36928       ['activation_196[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_183 (Batch  (None, 8, 8, 64)    256         ['conv2d_201[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_197 (Activation)    (None, 8, 8, 64)     0           ['batch_normalization_183[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_202 (Conv2D)            (None, 8, 8, 64)     36928       ['activation_197[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_184 (Batch  (None, 8, 8, 64)    256         ['conv2d_202[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_71 (Add)                   (None, 8, 8, 64)     0           ['activation_196[0][0]',         \n",
            "                                                                  'batch_normalization_184[0][0]']\n",
            "                                                                                                  \n",
            " activation_198 (Activation)    (None, 8, 8, 64)     0           ['add_71[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_203 (Conv2D)            (None, 8, 8, 64)     36928       ['activation_198[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_185 (Batch  (None, 8, 8, 64)    256         ['conv2d_203[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_199 (Activation)    (None, 8, 8, 64)     0           ['batch_normalization_185[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_204 (Conv2D)            (None, 8, 8, 64)     36928       ['activation_199[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_186 (Batch  (None, 8, 8, 64)    256         ['conv2d_204[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_72 (Add)                   (None, 8, 8, 64)     0           ['activation_198[0][0]',         \n",
            "                                                                  'batch_normalization_186[0][0]']\n",
            "                                                                                                  \n",
            " activation_200 (Activation)    (None, 8, 8, 64)     0           ['add_72[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_205 (Conv2D)            (None, 8, 8, 64)     36928       ['activation_200[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_187 (Batch  (None, 8, 8, 64)    256         ['conv2d_205[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_201 (Activation)    (None, 8, 8, 64)     0           ['batch_normalization_187[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_206 (Conv2D)            (None, 8, 8, 64)     36928       ['activation_201[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_188 (Batch  (None, 8, 8, 64)    256         ['conv2d_206[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_73 (Add)                   (None, 8, 8, 64)     0           ['activation_200[0][0]',         \n",
            "                                                                  'batch_normalization_188[0][0]']\n",
            "                                                                                                  \n",
            " activation_202 (Activation)    (None, 8, 8, 64)     0           ['add_73[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_207 (Conv2D)            (None, 8, 8, 64)     36928       ['activation_202[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_189 (Batch  (None, 8, 8, 64)    256         ['conv2d_207[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " activation_203 (Activation)    (None, 8, 8, 64)     0           ['batch_normalization_189[0][0]']\n",
            "                                                                                                  \n",
            " conv2d_208 (Conv2D)            (None, 8, 8, 64)     36928       ['activation_203[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_190 (Batch  (None, 8, 8, 64)    256         ['conv2d_208[0][0]']             \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " add_74 (Add)                   (None, 8, 8, 64)     0           ['activation_202[0][0]',         \n",
            "                                                                  'batch_normalization_190[0][0]']\n",
            "                                                                                                  \n",
            " activation_204 (Activation)    (None, 8, 8, 64)     0           ['add_74[0][0]']                 \n",
            "                                                                                                  \n",
            " average_pooling2d_3 (AveragePo  (None, 1, 1, 64)    0           ['activation_204[0][0]']         \n",
            " oling2D)                                                                                         \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)            (None, 64)           0           ['average_pooling2d_3[0][0]']    \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 10)           650         ['flatten_5[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 470,218\n",
            "Trainable params: 467,946\n",
            "Non-trainable params: 2,272\n",
            "__________________________________________________________________________________________________\n",
            "ResNet32v1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare model model saving directory.\n",
        "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
        "model_name1 = 'cifar10_%s_model.{epoch:03d}.h5' % model_type1\n",
        "if not os.path.isdir(save_dir):\n",
        "    os.makedirs(save_dir)\n",
        "filepath = os.path.join(save_dir, model_name1)\n",
        "\n",
        "# Prepare callbacks for model saving and for learning rate adjustment.\n",
        "checkpoint = ModelCheckpoint(filepath=filepath,\n",
        "                             monitor='val_acc',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True)\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
        "                               cooldown=0,\n",
        "                               patience=5,\n",
        "                               min_lr=0.5e-6)\n",
        "\n",
        "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
        "\n",
        "# Run training, with or without data augmentation.\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model1.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs1,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True,\n",
        "              callbacks=callbacks)\n",
        "else:\n",
        "    print('Using real-time data augmentation.')\n",
        "    # This will do preprocessing and realtime data augmentation:\n",
        "    datagen = ImageDataGenerator(\n",
        "        # set input mean to 0 over the dataset\n",
        "        featurewise_center=False,\n",
        "        # set each sample mean to 0\n",
        "        samplewise_center=False,\n",
        "        # divide inputs by std of dataset\n",
        "        featurewise_std_normalization=False,\n",
        "        # divide each input by its std\n",
        "        samplewise_std_normalization=False,\n",
        "        # apply ZCA whitening\n",
        "        zca_whitening=False,\n",
        "        # epsilon for ZCA whitening\n",
        "        zca_epsilon=1e-06,\n",
        "        # randomly rotate images in the range (deg 0 to 180)\n",
        "        rotation_range=0,\n",
        "        # randomly shift images horizontally\n",
        "        width_shift_range=0.1,\n",
        "        # randomly shift images vertically\n",
        "        height_shift_range=0.1,\n",
        "        # set range for random shear\n",
        "        shear_range=0.,\n",
        "        # set range for random zoom\n",
        "        zoom_range=0.,\n",
        "        # set range for random channel shifts\n",
        "        channel_shift_range=0.,\n",
        "        # set mode for filling points outside the input boundaries\n",
        "        fill_mode='nearest',\n",
        "        # value used for fill_mode = \"constant\"\n",
        "        cval=0.,\n",
        "        # randomly flip images\n",
        "        horizontal_flip=True,\n",
        "        # randomly flip images\n",
        "        vertical_flip=False,\n",
        "        # set rescaling factor (applied before any other transformation)\n",
        "        rescale=None,\n",
        "        # set function that will be applied on each input\n",
        "        preprocessing_function=None,\n",
        "        # image data format, either \"channels_first\" or \"channels_last\"\n",
        "        data_format=None,\n",
        "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
        "        validation_split=0.0)\n",
        "\n",
        "    # Compute quantities required for featurewise normalization\n",
        "    # (std, mean, and principal components if ZCA whitening is applied).\n",
        "    datagen.fit(x_train)\n",
        "\n",
        "    # Fit the model on the batches generated by datagen.flow().\n",
        "    model1.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
        "                        validation_data=(x_test, y_test),\n",
        "                        epochs=epochs1, verbose=1, workers=4,\n",
        "                        steps_per_epoch=steps_per_epoch,\n",
        "                        callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWTxSWARkzuf",
        "outputId": "9de90186-817c-4fa8-f620-f38aa858710a"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using real-time data augmentation.\n",
            "Learning rate:  0.001\n",
            "Epoch 1/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:86: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - ETA: 0s - loss: 1.6572 - accuracy: 0.4891"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1563 [==============================] - 741s 447ms/step - loss: 1.6572 - accuracy: 0.4891 - val_loss: 2.0613 - val_accuracy: 0.4513 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 2/4\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.2246 - accuracy: 0.6450"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1563 [==============================] - 721s 461ms/step - loss: 1.2246 - accuracy: 0.6450 - val_loss: 1.2315 - val_accuracy: 0.6576 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 3/4\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 1.0544 - accuracy: 0.7093"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1563 [==============================] - 718s 460ms/step - loss: 1.0544 - accuracy: 0.7093 - val_loss: 1.0069 - val_accuracy: 0.7289 - lr: 0.0010\n",
            "Learning rate:  0.001\n",
            "Epoch 4/4\n",
            "1563/1563 [==============================] - ETA: 0s - loss: 0.9637 - accuracy: 0.7397"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1563/1563 [==============================] - 725s 464ms/step - loss: 0.9637 - accuracy: 0.7397 - val_loss: 1.0657 - val_accuracy: 0.7098 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Score trained model.\n",
        "scores2 = model1.evaluate(x_test, y_test, verbose=1)\n",
        "resnetmodel2acc = scores2[1]\n",
        "print('Test loss:', scores2[0])\n",
        "print('Test accuracy:', scores2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkF_T3EXkzsW",
        "outputId": "7963a19d-6312-408f-8dcb-07aaf977e0e6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 31s 98ms/step - loss: 1.0657 - accuracy: 0.7098\n",
            "Test loss: 1.0656744241714478\n",
            "Test accuracy: 0.7098000049591064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy Comparison of ResNet Models\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"Testing Accuarcy of Original ResNet Model ResNet20\")\n",
        "print(\"Testing Accuracy:\",(resnetmodel1acc)*100,\"%\")\n",
        "print(\"\")\n",
        "print(\"--------------------------------------------\")\n",
        "print(\"Testing Accuarcy of ResNet Model with different model type ResNet32\")\n",
        "print(\"Testing Accuracy:\",(resnetmodel2acc)*100,\"%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuplFj6_lDib",
        "outputId": "46f72f35-3f96-45d3-c636-024f60e87eac"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------\n",
            "Testing Accuarcy of Original ResNet Model ResNet20\n",
            "Testing Accuracy: 71.8500018119812 %\n",
            "\n",
            "--------------------------------------------\n",
            "Testing Accuarcy of ResNet Model with different model type ResNet32\n",
            "Testing Accuracy: 70.98000049591064 %\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}